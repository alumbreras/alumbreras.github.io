<!DOCTYPE html>
<html lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

        <title>Alberto Lumbreras - Preference elicitation with Metropolis-Hastings</title>

        <link rel="stylesheet" type="text/css" href="//netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css" />
        <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.1/css/font-awesome.css" rel="stylesheet">

        <link rel="stylesheet" type="text/css" href="../css/syntax.css" />
        <link rel="stylesheet" type="text/css" href="../css/custom.css" />
        <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <div class="container">
            <div class="row">
                <div class="col-md-10 col-md-offset-2">
                    <h1 style="color:rgba(153, 153, 153, 0.0);">Alberto Lumbreras
                        <small>
                            <font size="4" style="color:rgba(153, 153, 153, 0.0);">[PhD Student in Computer Science]</font>
                        </small>
                    </h1>
                </div>
            </div>
            <div class="row">
                <div class="col-md-1">
                    <br />
                    <ul class="nav nav-stacked affix" data-spy="affix" data-offset-top="0">
                        <li><a href="../"><i class="fa fa-home fa-lg fa-fw"></i> Home</a></li>
                        <li><a href="../publications.html"><i class="fa fa-list fa-lg fa-fw"></i> Publications</a></li>
                        <li><a href="../posts.html"><i class="fa fa-pencil fa-lg fa-fw"></i> Posts</a></li>
                        <!-- <li><a href="/about.html"><i class="fa fa-male fa-lg fa-fw"></i> About</a></li> -->
                        <li><a href="http://github.com/alumbreras"><i class="fa fa-github fa-lg fa-fw"></i> GitHub</a></li>
                        <li><a href="https://twitter.com/albertlumbreras"><i class="fa fa-twitter fa-lg fa-fw"></i> Twitter</a></li>
                        <li><a href="http://es.linkedin.com/in/albertolumbreras"><i class="fa fa-linkedin fa-lg fa-fw"></i> LinkedIn</a></li> 

                    </ul>
                </div>
                <div class="col-md-10" style="top: -22px;">
                    <h3>Preference elicitation with Metropolis-Hastings</h3>

<small><a href="../posts/2015-04-26-Pairwise-preference_learning-with-Metropolis.html">Posted on April 26, 2015</a></small>

<p>(draft)</p>
<h4 id="theory">Theory</h4>
<p>Imagine we observe a set of pairwise preferences from a user. We denote this set by <span class="math">\(\mathcal{D} = \left \{ \mathbf{x}_i \succ \mathbf{x}_j \right \}\)</span> where <span class="math">\(1 \leq i \leq m\)</span> and <span class="math">\(1 \leq j \leq m\)</span>. Let us assume that the pairwise preferences depend on a latent utility <span class="math">\(f_i\)</span> given to every item <span class="math">\(i \in X\)</span> so that item <span class="math">\(i\)</span> is prefered over item <span class="math">\(j\)</span> iff utility of <span class="math">\(i\)</span> is bigger than utility of <span class="math">\(j\)</span>.</p>
<p>We want to know the posterior distribution of <span class="math">\(\mathbf{f}\)</span>, that is, the probability distribution of the utilities <span class="math">\(\mathbf{f}\)</span> after observing the data. For this we need a prior distribution over <span class="math">\(\mathbf{f}\)</span> and a likelihood function of the data given the utilities <span class="math">\(\mathbf{f}\)</span>.</p>
<p><strong>Likelihood</strong><br />If we knew these utility function, and assuming some noise <span class="math">\(\lambda\)</span> over the observed choices, we could model the likelihood of a pairwise choice as: <span class="math">\[
p(i \succ j | f) = \Phi(\frac{f_i - f_j}{\lambda})
\]</span> where <span class="math">\(\Phi\)</span> is the probit function.</p>
<p><strong>Prior</strong><br />We put a Gaussian prior over the utilities so that the <span class="math">\(m\)</span> utilities are drawn from the same Gaussian distribution. <span class="math">\[
p(f) = \mathcal{N}(f | 0, \mathbf{K})
\]</span></p>
<p>Note that this is actually a Gaussian Process, since if we take any subset of utilities <span class="math">\(f_s\)</span>: <span class="math">\[
p(f_s) = \mathcal{N}(f_s | 0, \mathbf{K_s})
\]</span></p>
<p><strong>Posterior</strong><br />The posterior distribution is given by Bayes rule: <span class="math">\[
p(f | \mathbf{X}) = \frac{\prod_{(i,j) \in \mathcal{D}}  p(i \succ j | f) p(f | 0, \mathbf{K})}
{\int_f \prod_{(i,j) \in \mathcal{D}}  p(i \succ j | f) p(f | 0, \mathbf{K})}
\]</span> but we cannot solve the integral in the denominator. Instead, we will take samples from: <span class="math">\[
p(f | \mathbf{X}) \propto \prod_{(i,j) \in \mathcal{D}}  p(i \succ j | f) p(f | 0, \mathbf{K})
\]</span> and we will do it with the very simple <a href="http://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm">Metropolis-Hastings</a>.</p>
<h4 id="practice-with-r">Practice with R</h4>
<p>First, let us generate some toy data:</p>
<pre class="sourceCode r"><code class="sourceCode r">############################
<span class="co"># Data (manual generation)</span>
############################
<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(MASS)
<span class="kw">library</span>(mvtnorm)
<span class="kw">library</span>(corrplot)  

pairs &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">8</span>,<span class="dv">9</span>,<span class="dv">9</span>,<span class="dv">10</span>), 
                    <span class="dt">nrow=</span><span class="dv">2</span>, <span class="dt">ncol=</span><span class="dv">9</span>))

<span class="co"># Replicate observations</span>
pairs &lt;-<span class="st"> </span><span class="kw">do.call</span>(rbind, <span class="kw">replicate</span>(<span class="dv">3</span>, pairs, <span class="dt">simplify=</span>F))

<span class="co"># Number of items</span>
L &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">unique</span>(<span class="kw">c</span>(pairs)))

<span class="co"># or...</span>
###############################
<span class="co"># Data (stochastic generation)</span>
###############################
npairs &lt;-<span class="st"> </span><span class="dv">100</span>
L &lt;-<span class="st"> </span><span class="dv">10</span>
fu &lt;-<span class="st"> </span><span class="kw">seq</span>(L)/L
lambda &lt;-<span class="st"> </span><span class="fl">0.01</span> <span class="co"># lambda is like the noise in the choices</span>
items1 &lt;-<span class="st"> </span><span class="kw">sample</span>(L,npairs, <span class="dt">replace=</span>T)
items2 &lt;-<span class="st"> </span><span class="kw">sample</span>(L,npairs, <span class="dt">replace=</span>T)
pairs &lt;-<span class="st"> </span><span class="kw">cbind</span>(items1, items2)
probs &lt;-<span class="st"> </span><span class="kw">pnorm</span>((fu[pairs[,<span class="dv">1</span>]] -<span class="st"> </span>fu[pairs[,<span class="dv">2</span>]])/lambda)
for(i in <span class="dv">1</span>:npairs){
  if (<span class="kw">runif</span>(<span class="dv">1</span>) &gt;<span class="st"> </span>probs[i]){
    pairs[i,] &lt;-<span class="st"> </span><span class="kw">rev</span>(pairs[i,])
  }
}</code></pre>
<p>Let us design the covariance matrix <span class="math">\(\mathbf{K}\)</span> in such a way that covariance between items is proportional to items similarity. We need a similarity metric such as:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># kernel function to build the covariance matrix of the prior</span>
kernel &lt;-<span class="st"> </span>function(x1,x2) {<span class="kw">exp</span>(-(x1-x2)^<span class="dv">2</span>)}</code></pre>
<p>And now we build the covariance:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Covariance matrix</span>
Sigma &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, L, L)
for(i in <span class="dv">1</span>:L){
  for (j in i:L){
    Sigma[i,j] &lt;-<span class="st"> </span><span class="kw">kernel</span>(i,j)
    Sigma[j,i] &lt;-<span class="st"> </span>Sigma[i,j]
  }
}

<span class="co"># Plot covariance matrix</span>
<span class="kw">corrplot</span>(Sigma, <span class="dt">method=</span><span class="st">&quot;shade&quot;</span>)</code></pre>
<div class="figure">
<img src="../images/2015-04-26-Sigma.png" />
</div>
<p>Now we can build our prior:</p>
<pre class="sourceCode r"><code class="sourceCode r">prior &lt;-<span class="st"> </span>function(f) { <span class="kw">dmvnorm</span>(f, <span class="kw">rep</span>(<span class="dv">0</span>,L), Sigma, <span class="dt">log=</span><span class="ot">TRUE</span>) }</code></pre>
<p>The likelihood is:</p>
<pre class="sourceCode r"><code class="sourceCode r">likelihood &lt;-<span class="st"> </span>function(x1, x2, f) { <span class="kw">log</span>(<span class="kw">pnorm</span>((f[x1]-f[x2])/lambda)) }</code></pre>
<p>The posterior is proportional the the likelihood times the prior:</p>
<pre class="sourceCode r"><code class="sourceCode r">posterior &lt;-<span class="st"> </span>function(pairs, f){
  npairs &lt;-<span class="st"> </span><span class="kw">dim</span>(pairs)[<span class="dv">1</span>]
  like &lt;-<span class="st"> </span><span class="dv">0</span>
  <span class="co"># total likelihood</span>
  for(i in <span class="dv">1</span>:npairs){
    like &lt;-<span class="st"> </span>like +<span class="st"> </span><span class="kw">likelihood</span>(pairs[i,<span class="dv">1</span>], pairs[i,<span class="dv">2</span>], f) 
  }
  <span class="co"># prior</span>
  like &lt;-<span class="st"> </span>like +<span class="st"> </span><span class="kw">prior</span>(f)
  <span class="kw">return</span>(like)
}</code></pre>
<p>A Metropolis-Hasting implementation with its proposal distribution:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Proposal distribution</span>
step &lt;-<span class="st"> </span><span class="fl">0.0001</span> <span class="co"># tune it so that around 20% of samples are accepted</span>
rproposal &lt;-<span class="st"> </span>function(x){x +<span class="st"> </span><span class="kw">mvrnorm</span>(<span class="dv">1</span>, <span class="kw">rep</span>(<span class="dv">0</span>,L), <span class="kw">diag</span>(L)*step)}

<span class="co"># Metropolis-Hastings</span>
metropolis &lt;-<span class="st"> </span>function(nsamples, pairs){
  chain &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, nsamples, L)
  f &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>,L)
  chain[<span class="dv">1</span>,] &lt;-<span class="st"> </span>f
  for(i in <span class="dv">2</span>:nsamples){
    proposal &lt;-<span class="st"> </span><span class="kw">rproposal</span>(chain[i,])
    ratio &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="kw">posterior</span>(pairs, proposal) -<span class="st"> </span><span class="kw">posterior</span>(pairs, chain[i<span class="dv">-1</span>,]))
    if (<span class="kw">runif</span>(<span class="dv">1</span>) &lt;<span class="st"> </span>ratio){
      chain[i,] &lt;-<span class="st"> </span>proposal
    }
    else{
      chain[i,] &lt;-<span class="st"> </span>chain[i<span class="dv">-1</span>,]
    }
  }
  <span class="kw">return</span>(chain)
}</code></pre>
<p>And finally we use our Metropolis-Hastings to infer the utility function of the items based on the observed choices:</p>
<pre class="sourceCode r"><code class="sourceCode r">chain &lt;-<span class="st"> </span><span class="kw">metropolis</span>(<span class="dv">10000</span>, pairs)

burnIn &lt;-<span class="st"> </span><span class="kw">dim</span>(chain)[<span class="dv">1</span>]*<span class="fl">0.5</span>
chain &lt;-<span class="st"> </span>chain[<span class="dv">1</span>:burnIn,]
acceptance &lt;-<span class="st"> </span><span class="dv">1</span>-<span class="kw">mean</span>(<span class="kw">duplicated</span>(chain))
<span class="kw">cat</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Acceptance rate&quot;</span>, acceptance)

means &lt;-<span class="st"> </span><span class="kw">apply</span>(chain, <span class="dv">2</span>, mean)
estimated.rank &lt;-<span class="st"> </span><span class="kw">order</span>(means, <span class="dt">decreasing=</span><span class="ot">TRUE</span>)
<span class="kw">cat</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Estimated rank (posterior mean)&quot;</span>, estimated.rank)

<span class="co"># Plot posterior with credible intervals</span>
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))
<span class="kw">plot</span>(<span class="kw">seq</span>(<span class="dv">10</span>), means)
credible.intervals &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="kw">apply</span>(chain, <span class="dv">2</span>, function(x) <span class="kw">quantile</span>(x, <span class="kw">c</span>(<span class="fl">0.25</span>,<span class="fl">0.75</span>))))
L &lt;-<span class="st"> </span>credible.intervals[,<span class="dv">1</span>]
U &lt;-<span class="st"> </span>credible.intervals[,<span class="dv">2</span>]
x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">10</span>)
<span class="kw">qplot</span>(x, means) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(<span class="dt">ymin=</span>L, <span class="dt">ymax=</span>U)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;items&quot;</span>) +<span class="st"> </span><span class="kw">ylab</span>(<span class="st">&quot;f&quot;</span>) +<span class="st">  </span><span class="kw">scale_x_discrete</span>(<span class="dt">limits=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">10</span>)) +
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Posterior of the utility function (credible intervals at 50%)&quot;</span>)</code></pre>
<p><img src="../images/2015-04-26-posterior.png" width="800px"></p>

<div class="panel panel-default">
    <div class="panel-body">
        <div class="pull-left">
            Tags: <a href="../tags/tutorials.html">tutorials</a>, <a href="../tags/bayesian%20statistics.html">bayesian statistics</a>, <a href="../tags/bayesian%20inference.html">bayesian inference</a>, <a href="../tags/metropolis-hastings.html">metropolis-hastings</a>
        </div>
        <div class="social pull-right">
            <span class="twitter">
                <a href="https://twitter.com/share" class="twitter-share-button" data-url="http://www.albertolumbreras.net/posts/2015-04-26-Pairwise-preference_learning-with-Metropolis.html" data-via="albertlumbreras" data-dnt="true">Tweet</a>
            </span>
        </div>
    </div>
</div>

<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = 'albertolumbreras';
    
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
     var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
     dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
     (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();
    </script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
                </div>
            </div>
        </div>

  
        <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
             (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
             m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
             })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
            
            ga('create', 'UA-62494759-1', 'auto');
            ga('send', 'pageview');
            
            </script>
        
    </body>
</html>
