---
layout: ai-note
title: Group Relative Policy Optimization (GRPO)
category: "Large Language Models"
date: 2024-10-31
tags: reinforcement-learning, llm, policy-optimization
---

ðŸš§ **Work in progress...**

This article will cover Group Relative Policy Optimization (GRPO), a recent advancement in policy optimization methods for training language models with human preferences.

## Topics to cover:
- Motivation: improving upon PPO and DPO
- GRPO algorithm and key innovations
- Group-based relative preference modeling
- Empirical results and comparisons
